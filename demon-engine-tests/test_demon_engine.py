# ðŸ§ª DEMON ENGINE TESTS - Because Even Legendary Systems Need QA
"""
Comprehensive test suite for the Demon Engine
Tests core functionality, API endpoints, and integration scenarios
"""

import pytest
import asyncio
import json
from httpx import AsyncClient
from unittest.mock import Mock, patch, AsyncMock
from datetime import datetime

# Import Demon Engine components
from demon_engine.core import DemonEngineBrain
from demon_engine.schemas import (
    DemonEngineRequest, DemonEngineConfig, TechniqueCore,
    QueryAnalysis, DifficultyLevel, CategoryType
)
from demon_engine.api import app
from demon_engine.helpers import DemonEngineHelpers

@pytest.fixture
def mock_db():
    """Mock MongoDB database"""
    mock_db = Mock()
    mock_db.__getitem__ = Mock(return_value=Mock())
    return mock_db

@pytest.fixture
def mock_config():
    """Mock Demon Engine configuration"""
    return DemonEngineConfig()

@pytest.fixture
def sample_technique():
    """Sample technique for testing"""
    return TechniqueCore(
        id="test_technique_001",
        name="Test Chain of Thought",
        description="A test technique for chain of thought reasoning",
        category=CategoryType.REASONING,
        tags=["test", "reasoning", "cot"],
        template="Think step by step: {query}",
        example="Think step by step: What is 2+2? First, I identify this is addition...",
        use_cases=["Mathematical reasoning", "Problem solving"],
        difficulty=DifficultyLevel.INTERMEDIATE,
        estimated_tokens=150,
        performance_score=0.85,
        success_rate=0.9,
        aliases=["cot", "chain_of_thought"],
        complementary_techniques=["step_by_step", "reasoning_framework"],
        conflicts_with=["quick_answer", "single_shot"],
        usage_frequency=100,
        description_embedding=[0.1] * 384  # Mock embedding
    )

@pytest.fixture
def sample_query_analysis():
    """Sample query analysis for testing"""
    return QueryAnalysis(
        raw_query="Explain how photosynthesis works",
        cleaned_query="explain how photosynthesis works",
        intent_type="explanation",
        complexity_level=DifficultyLevel.INTERMEDIATE,
        output_format_requested=None,
        tone_requested=None,
        constraints=[],
        pfcl_commands=[],
        query_embedding=[0.2] * 384,  # Mock embedding
        confidence_score=0.9
    )

class TestDemonEngineBrain:
    """ðŸ§  Test the core Demon Engine Brain functionality"""
    
    @pytest.mark.asyncio
    async def test_initialization(self, mock_config, mock_db):
        """Test Demon Engine Brain initialization"""
        brain = DemonEngineBrain(mock_config, mock_db)
        assert brain.config == mock_config
        assert brain.db == mock_db
        assert brain._technique_cache == {}
        
    @pytest.mark.asyncio
    async def test_query_analysis(self, mock_config, mock_db):
        """Test query analysis functionality"""
        brain = DemonEngineBrain(mock_config, mock_db)
        
        query = "Create a business plan for an AI startup"
        analysis = await brain._analyze_query(query)
        
        assert analysis.raw_query == query
        assert analysis.cleaned_query == query.lower()
        assert analysis.intent_type == "creative"
        assert len(analysis.query_embedding) > 0
        
    @pytest.mark.asyncio
    async def test_technique_scoring(self, mock_config, mock_db, sample_technique, sample_query_analysis):
        """Test technique scoring and selection"""
        brain = DemonEngineBrain(mock_config, mock_db)
        brain._technique_cache[sample_technique.id] = sample_technique
        
        # Test signal boost calculation
        signal_boost = brain._calculate_signal_boost(sample_technique, sample_query_analysis)
        assert isinstance(signal_boost, float)
        assert 0 <= signal_boost <= 0.5
        
        # Test penalty calculation
        penalty = brain._calculate_penalties(sample_technique, sample_query_analysis, 
                                           DemonEngineRequest(query="test"))
        assert isinstance(penalty, float)
        assert 0 <= penalty <= 0.5

class TestDemonEngineHelpers:
    """ðŸ”§ Test the helper functions"""
    
    def test_generate_selection_reason(self, sample_technique, sample_query_analysis):
        """Test selection reason generation"""
        reason = DemonEngineHelpers.generate_selection_reason(
            sample_technique, sample_query_analysis, 0.8
        )
        assert isinstance(reason, str)
        assert len(reason) > 0
        assert "high semantic similarity" in reason or "semantic" in reason
        
    def test_determine_execution_order(self, sample_technique):
        """Test execution order determination"""
        from demon_engine.schemas import TechniqueScore
        
        scores = [
            TechniqueScore(
                technique_id="foundation_001",
                technique_name="Foundation Technique",
                semantic_score=0.8,
                signal_boost=0.1,
                penalty_score=0.0,
                final_score=0.9,
                selection_reason="test"
            ),
            TechniqueScore(
                technique_id="meta_001", 
                technique_name="Meta Framework",
                semantic_score=0.7,
                signal_boost=0.1,
                penalty_score=0.0,
                final_score=0.8,
                selection_reason="test"
            )
        ]
        
        order = DemonEngineHelpers.determine_execution_order(scores)
        assert isinstance(order, list)
        assert len(order) == 2
        # Foundation technique should come before meta framework
        assert order[0] == 0  # Index of foundation technique
        
    def test_output_validation(self, sample_query_analysis):
        """Test output validation"""
        # Test valid JSON
        json_output = '{"result": "success", "data": [1, 2, 3]}'
        sample_query_analysis.output_format_requested = "json"
        
        is_valid, errors = asyncio.run(
            DemonEngineHelpers.validate_output(json_output, sample_query_analysis)
        )
        assert is_valid
        assert len(errors) == 0
        
        # Test invalid JSON
        invalid_json = '{"result": "success", "data": [1, 2, 3'
        is_valid, errors = asyncio.run(
            DemonEngineHelpers.validate_output(invalid_json, sample_query_analysis)
        )
        assert not is_valid
        assert len(errors) > 0
        
    def test_fidelity_score_calculation(self, sample_query_analysis):
        """Test fidelity score calculation"""
        output = "Photosynthesis is the process by which plants convert sunlight into energy"
        
        score = asyncio.run(
            DemonEngineHelpers.calculate_fidelity_score(output, sample_query_analysis)
        )
        assert isinstance(score, float)
        assert 0 <= score <= 1
        
    def test_json_parsing(self):
        """Test JSON parsing utility"""
        # Valid JSON
        valid_json = '{"key": "value", "number": 42}'
        result = DemonEngineHelpers.try_parse_json(valid_json)
        assert result == {"key": "value", "number": 42}
        
        # Invalid JSON
        invalid_json = 'not json at all'
        result = DemonEngineHelpers.try_parse_json(invalid_json)
        assert result is None

class TestAPI:
    """ðŸŒ Test the FastAPI endpoints"""
    
    @pytest.mark.asyncio
    async def test_root_endpoint(self):
        """Test the root endpoint"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/")
        
        assert response.status_code == 200
        data = response.json()
        assert "message" in data
        assert "Demon Engine" in data["message"]
        
    @pytest.mark.asyncio 
    @patch('demon_engine.api.demon_brain')
    async def test_prompt_endpoint_success(self, mock_brain):
        """Test successful prompt processing"""
        # Mock the brain response
        mock_response = Mock()
        mock_response.success = True
        mock_response.output = "This is a test response"
        mock_response.techniques_used = ["technique_001"]
        mock_response.execution_time_ms = 1500
        mock_response.quality_score = 0.85
        
        mock_brain.process_query = AsyncMock(return_value=mock_response)
        
        request_data = {
            "query": "Test query",
            "explain": False,
            "max_techniques": 5
        }
        
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.post("/prompt", json=request_data)
        
        assert response.status_code == 200
        # Note: This test would need proper app initialization to pass completely
        
    @pytest.mark.asyncio
    async def test_health_endpoint_structure(self):
        """Test health endpoint structure (without DB)"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/health")
        
        # Should return some response (might be unhealthy without real DB)
        assert response.status_code == 200
        data = response.json()
        assert "status" in data
        assert "timestamp" in data

class TestIntegration:
    """ðŸ”€ Integration tests"""
    
    @pytest.mark.asyncio
    @patch('demon_engine.core.AsyncIOMotorClient')
    @patch('openai.AsyncOpenAI')
    async def test_full_pipeline_mock(self, mock_openai, mock_mongo):
        """Test full pipeline with mocked dependencies"""
        # Mock MongoDB
        mock_collection = Mock()
        mock_collection.aggregate.return_value.to_list = AsyncMock(return_value=[])
        mock_collection.count_documents = AsyncMock(return_value=0)
        mock_collection.bulk_write = AsyncMock()
        
        mock_db = Mock()
        mock_db.__getitem__ = Mock(return_value=mock_collection)
        
        # Mock OpenAI
        mock_openai_response = Mock()
        mock_openai_response.choices = [Mock(message=Mock(content="Test response"))]
        mock_openai_response.usage = Mock(total_tokens=150)
        
        mock_openai_client = Mock()
        mock_openai_client.chat.completions.create = AsyncMock(return_value=mock_openai_response)
        mock_openai.return_value = mock_openai_client
        
        # Test the pipeline
        config = DemonEngineConfig()
        brain = DemonEngineBrain(config, mock_db)
        
        request = DemonEngineRequest(
            query="Test query for integration",
            explain=False
        )
        
        # This would need techniques in cache to work fully
        brain._technique_cache["test_001"] = TechniqueCore(
            id="test_001",
            name="Test Technique",
            description="Test description",
            category=CategoryType.FOUNDATIONAL,
            tags=["test"],
            template="Test template",
            use_cases=["testing"],
            difficulty=DifficultyLevel.BEGINNER,
            estimated_tokens=100,
            description_embedding=[0.1] * 384
        )
        
        # The test would continue with actual pipeline execution...
        # For brevity, we're testing the setup here

@pytest.mark.asyncio
async def test_schema_validation():
    """ðŸ” Test Pydantic schema validation"""
    # Test valid request
    valid_request = DemonEngineRequest(
        query="Test query",
        explain=True,
        max_techniques=5
    )
    assert valid_request.query == "Test query"
    assert valid_request.explain is True
    
    # Test invalid data (should raise ValidationError)
    with pytest.raises(Exception):  # Pydantic ValidationError
        DemonEngineRequest(
            query="",  # Empty query should fail validation
            max_techniques=-1  # Negative value should fail
        )

def test_difficulty_enum():
    """Test difficulty level enum"""
    assert DifficultyLevel.BEGINNER == "beginner"
    assert DifficultyLevel.INTERMEDIATE == "intermediate" 
    assert DifficultyLevel.ADVANCED == "advanced"
    assert DifficultyLevel.EXPERT == "expert"

def test_category_enum():
    """Test category type enum"""
    assert CategoryType.FOUNDATIONAL == "foundational"
    assert CategoryType.REASONING == "reasoning"
    assert CategoryType.CREATIVE_AND_GENERATIVE == "creative_and_generative"

if __name__ == "__main__":
    # Run tests with pytest
    pytest.main([__file__, "-v", "--tb=short"])
